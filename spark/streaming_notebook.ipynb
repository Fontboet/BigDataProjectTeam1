{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spark Streaming Flight Analysis Pipeline\n",
        "\n",
        "This notebook implements a real-time flight data processing pipeline using Spark Streaming, Kafka, and Cassandra.\n",
        "\n",
        "## Architecture\n",
        "1. **Ingest**: Read JSON flight data from Kafka topic `flights_topic`.\n",
        "2. **Process**: \n",
        "    - Parse JSON payload.\n",
        "    - Join with static airport and airline reference data.\n",
        "    - Aggregate metrics for Airline Performance, Delay Reasons, and Routes.\n",
        "3. **Store**: Write aggregated results to Cassandra tables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n",
        "Initialize SparkSession with Cassandra and Kafka connectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "894795a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "your 131072x1 screen size is bogus. expect trouble\n",
            "25/12/26 16:07:29 WARN Utils: Your hostname, DESKTOP-VS2UPJ4 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
            "25/12/26 16:07:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ":: loading settings :: url = jar:file:/home/anhtu77/miniconda3/envs/datalab/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ivy Default Cache set to: /home/anhtu77/.ivy2/cache\n",
            "The jars for the packages stored in: /home/anhtu77/.ivy2/jars\n",
            "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
            "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4fc38d75-1704-49d2-8340-af73f3f492a7;1.0\n",
            "\tconfs: [default]\n",
            "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3 in central\n",
            "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3 in central\n",
            "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
            "\tfound org.lz4#lz4-java;1.8.0 in central\n",
            "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
            "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
            "\tfound commons-logging#commons-logging;1.1.3 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
            "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
            "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central\n",
            "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central\n",
            "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
            "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
            "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
            "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
            "\tfound com.typesafe#config;1.4.1 in central\n",
            "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
            "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
            "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
            "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
            "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
            "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
            "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
            "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
            "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
            "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
            ":: resolution report :: resolve 890ms :: artifacts dl 23ms\n",
            "\t:: modules in use:\n",
            "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
            "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
            "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
            "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
            "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
            "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]\n",
            "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]\n",
            "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
            "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
            "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
            "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
            "\tcom.typesafe#config;1.4.1 from central in [default]\n",
            "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
            "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
            "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
            "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
            "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
            "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3 from central in [default]\n",
            "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3 from central in [default]\n",
            "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
            "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
            "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
            "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
            "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
            "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
            "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
            "\t:: evicted modules:\n",
            "\tcom.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   30  |   0   |   0   |   2   ||   28  |   0   |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-4fc38d75-1704-49d2-8340-af73f3f492a7\n",
            "\tconfs: [default]\n",
            "\t0 artifacts copied, 28 already retrieved (0kB/12ms)\n",
            "25/12/26 16:07:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark Session Created Successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import from_json, col, current_timestamp, when, sum as _sum, avg, count\n",
        "from pyspark.sql.types import StructType, StringType, IntegerType\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"flights_stream_notebook\") \\\n",
        "    .config(\"spark.cassandra.connection.host\", os.environ.get(\"CASSANDRA_HOST\", \"cassandra\")) \\\n",
        "    .config(\"spark.cassandra.connection.port\", os.environ.get(\"CASSANDRA_PORT\", \"9042\")) \\\n",
        "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "print(\"Spark Session Created Successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d111cff2",
      "metadata": {},
      "source": [
        "## 2. Data Source Definitions\n",
        "Read streaming data from Kafka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3bb401ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to Kafka at localhost:9092, topic: flights_topic\n",
            "Kafka Source Initialized\n"
          ]
        }
      ],
      "source": [
        "kafka_bootstrap = os.environ.get(\"KAFKA_BOOTSTRAP_SERVERS\", \"localhost:9092\")\n",
        "kafka_topic = os.environ.get(\"KAFKA_TOPIC\", \"flights_topic\")\n",
        "\n",
        "print(f\"Connecting to Kafka at {kafka_bootstrap}, topic: {kafka_topic}\")\n",
        "\n",
        "kafka_flights_df = (spark.readStream.format(\"kafka\")\n",
        "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap)\n",
        "    .option(\"subscribe\", kafka_topic)\n",
        "    .option(\"startingOffsets\", \"earliest\")\n",
        "    .option(\"failOnDataLoss\", \"false\")\n",
        "    .load())\n",
        "\n",
        "print(\"Kafka Source Initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cbddc4f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 16:07:46 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-125b399e-2b61-412f-b0f7-3567c01b6c12. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "25/12/26 16:07:46 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            "25/12/26 16:07:46 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
            "25/12/26 16:07:56 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:07:57 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:07:57 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:07:57 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:07:57 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:07:58 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:07:59 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:00 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:01 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:02 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:03 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:04 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:05 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:06 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:17 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:18 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:19 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:20 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:21 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:22 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:23 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:24 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:25 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:26 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:37 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:38 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:39 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:40 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:41 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:42 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:43 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:44 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:45 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:08:46 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Use localhost when running outside Docker, or kafka:9092 inside Docker\n",
        "kafka_bootstrap = os.environ.get(\"KAFKA_BOOTSTRAP_SERVERS\", \"localhost:9092\")\n",
        "\n",
        "# Streaming DataFrames cannot use .show(); use a streaming sink such as the console for debugging.\n",
        "query = kafka_flights_df.selectExpr(\n",
        "    \"CAST(key AS STRING) as key\",\n",
        "    \"CAST(value AS STRING) as value\",\n",
        "    \"topic\", \"partition\", \"offset\", \"timestamp\"\n",
        ").writeStream \\\n",
        "    .format(\"console\") \\\n",
        "    .option(\"truncate\", False) \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .start()\n",
        "\n",
        "# Let the console sink run briefly to print a few batches, then stop.\n",
        "try:\n",
        "    time.sleep(5)\n",
        "finally:\n",
        "    query.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Schema Definition and Parsing\n",
        "Define the schema for flight data and parse the JSON value column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed Data Schema:\n",
            "root\n",
            " |-- YEAR: integer (nullable = true)\n",
            " |-- MONTH: integer (nullable = true)\n",
            " |-- DAY: integer (nullable = true)\n",
            " |-- DAY_OF_WEEK: integer (nullable = true)\n",
            " |-- AIRLINE: string (nullable = true)\n",
            " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
            " |-- TAIL_NUMBER: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
            " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
            " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
            " |-- DEPARTURE_TIME: integer (nullable = true)\n",
            " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
            " |-- TAXI_OUT: integer (nullable = true)\n",
            " |-- WHEELS_OFF: integer (nullable = true)\n",
            " |-- SCHEDULED_TIME: integer (nullable = true)\n",
            " |-- ELAPSED_TIME: integer (nullable = true)\n",
            " |-- AIR_TIME: integer (nullable = true)\n",
            " |-- DISTANCE: integer (nullable = true)\n",
            " |-- WHEELS_ON: integer (nullable = true)\n",
            " |-- TAXI_IN: integer (nullable = true)\n",
            " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
            " |-- ARRIVAL_TIME: integer (nullable = true)\n",
            " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
            " |-- DIVERTED: integer (nullable = true)\n",
            " |-- CANCELLED: integer (nullable = true)\n",
            " |-- CANCELLATION_REASON: string (nullable = true)\n",
            " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
            " |-- SECURITY_DELAY: integer (nullable = true)\n",
            " |-- AIRLINE_DELAY: integer (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
            " |-- WEATHER_DELAY: integer (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 16:08:56 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
          ]
        }
      ],
      "source": [
        "flights_schema = StructType() \\\n",
        "    .add(\"YEAR\", IntegerType()) \\\n",
        "    .add(\"MONTH\", IntegerType()) \\\n",
        "    .add(\"DAY\", IntegerType()) \\\n",
        "    .add(\"DAY_OF_WEEK\", IntegerType()) \\\n",
        "    .add(\"AIRLINE\", StringType()) \\\n",
        "    .add(\"FLIGHT_NUMBER\", IntegerType()) \\\n",
        "    .add(\"TAIL_NUMBER\", StringType()) \\\n",
        "    .add(\"ORIGIN_AIRPORT\", StringType()) \\\n",
        "    .add(\"DESTINATION_AIRPORT\", StringType()) \\\n",
        "    .add(\"SCHEDULED_DEPARTURE\", IntegerType()) \\\n",
        "    .add(\"DEPARTURE_TIME\", IntegerType()) \\\n",
        "    .add(\"DEPARTURE_DELAY\", IntegerType()) \\\n",
        "    .add(\"TAXI_OUT\", IntegerType()) \\\n",
        "    .add(\"WHEELS_OFF\", IntegerType()) \\\n",
        "    .add(\"SCHEDULED_TIME\", IntegerType()) \\\n",
        "    .add(\"ELAPSED_TIME\", IntegerType()) \\\n",
        "    .add(\"AIR_TIME\", IntegerType()) \\\n",
        "    .add(\"DISTANCE\", IntegerType()) \\\n",
        "    .add(\"WHEELS_ON\", IntegerType()) \\\n",
        "    .add(\"TAXI_IN\", IntegerType()) \\\n",
        "    .add(\"SCHEDULED_ARRIVAL\", IntegerType()) \\\n",
        "    .add(\"ARRIVAL_TIME\", IntegerType()) \\\n",
        "    .add(\"ARRIVAL_DELAY\", IntegerType()) \\\n",
        "    .add(\"DIVERTED\", IntegerType()) \\\n",
        "    .add(\"CANCELLED\", IntegerType()) \\\n",
        "    .add(\"CANCELLATION_REASON\", StringType()) \\\n",
        "    .add(\"AIR_SYSTEM_DELAY\", IntegerType()) \\\n",
        "    .add(\"SECURITY_DELAY\", IntegerType()) \\\n",
        "    .add(\"AIRLINE_DELAY\", IntegerType()) \\\n",
        "    .add(\"LATE_AIRCRAFT_DELAY\", IntegerType()) \\\n",
        "    .add(\"WEATHER_DELAY\", IntegerType())\n",
        "\n",
        "# Parse JSON\n",
        "flights_df = kafka_flights_df.select(\n",
        "    from_json(col(\"value\").cast(\"string\"), flights_schema).alias(\"data\")\n",
        ").select(\"data.*\")\n",
        "\n",
        "# Validation: Print Schema\n",
        "print(\"Parsed Data Schema:\")\n",
        "flights_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1720be06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stopping query: flights_table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 16:11:01 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:01 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:02 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:03 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:04 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:05 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:06 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:07 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:08 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:09 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:10 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:21 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:22 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:23 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/anhtu77/miniconda3/envs/datalab/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/home/anhtu77/miniconda3/envs/datalab/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/home/anhtu77/miniconda3/envs/datalab/lib/python3.10/socket.py\", line 717, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n",
            "25/12/26 16:11:24 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m spark\u001b[38;5;241m.\u001b[39mstreams\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m query_mem \u001b[38;5;241m=\u001b[39m flights_df\u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mqueryName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflights_table\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming Query Started, writing to in-memory table \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflights_table\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/pyspark/sql/streaming/query.py:372\u001b[0m, in \u001b[0;36mStreamingQuery.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    Stop this streaming query.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 16:11:25 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:26 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:27 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:28 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:29 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/26 16:11:30 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:9092 (id: 1 rack: null)\n",
            "java.net.UnknownHostException: kafka\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
            "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
            "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
            "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
            "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
          ]
        }
      ],
      "source": [
        "for q in spark.streams.active:\n",
        "    print(f\"Stopping query: {q.name}\")\n",
        "    q.stop()\n",
        "    \n",
        "query_mem = flights_df.writeStream \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"flights_table\") \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"Streaming Query Started, writing to in-memory table 'flights_table'\")\n",
        "# query_mem.awaitTermination()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Enrich with Static Data\n",
        "Load Airports and Airlines CSV data for joining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Static data loaded successfully\n",
            "Airports count: 322\n",
            "Airlines count: 14\n"
          ]
        }
      ],
      "source": [
        "# Load static reference data\n",
        "try:\n",
        "    airport_df = spark.read.csv('/home/anhtu77/Coding/BigDataProjectTeam1/data/airports.csv', header=True, inferSchema=True)\n",
        "    airline_df = spark.read.csv('/home/anhtu77/Coding/BigDataProjectTeam1/data/airlines.csv', header=True, inferSchema=True)\n",
        "    print(\"Static data loaded successfully\")\n",
        "    print(f\"Airports count: {airport_df.count()}\")\n",
        "    print(f\"Airlines count: {airline_df.count()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading static data: {e}\")\n",
        "    # Fallback or exit if critical\n",
        "\n",
        "# Prepare Airline DF\n",
        "airline_df = airline_df.withColumnRenamed(\"AIRLINE\", \"AIRLINES\")\n",
        "\n",
        "# Prepare Airport DFs for Origin and Destination\n",
        "airport_origin_df = airport_df.withColumnRenamed(\"IATA_CODE\", \"ORIGIN_AIRPORT_CODE\")\\\n",
        "    .withColumnRenamed(\"AIRPORT\", \"ORIGIN_AIRPORT_NAME\")\\\n",
        "    .withColumnRenamed(\"CITY\", \"ORIGIN_CITY\")\\\n",
        "    .withColumnRenamed(\"STATE\", \"ORIGIN_STATE\")\\\n",
        "    .withColumnRenamed(\"COUNTRY\", \"ORIGIN_COUNTRY\")\\\n",
        "    .withColumnRenamed(\"LATITUDE\", \"ORIGIN_LATITUDE\")\\\n",
        "    .withColumnRenamed(\"LONGITUDE\", \"ORIGIN_LONGITUDE\")\n",
        "\n",
        "airport_destination_df = airport_df.withColumnRenamed(\"IATA_CODE\", \"DESTINATION_AIRPORT_CODE\")\\\n",
        "    .withColumnRenamed(\"AIRPORT\", \"DESTINATION_AIRPORT_NAME\")\\\n",
        "    .withColumnRenamed(\"CITY\", \"DESTINATION_CITY\")\\\n",
        "    .withColumnRenamed(\"STATE\", \"DESTINATION_STATE\")\\\n",
        "    .withColumnRenamed(\"COUNTRY\", \"DESTINATION_COUNTRY\")\\\n",
        "    .withColumnRenamed(\"LATITUDE\", \"DESTINATION_LATITUDE\")\\\n",
        "    .withColumnRenamed(\"LONGITUDE\", \"DESTINATION_LONGITUDE\")\\\n",
        "    .withColumnRenamed(\"AIRLINE\", \"AIRLINES\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Transformations and Joins\n",
        "Join streaming flight data with static reference data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joins Defined\n"
          ]
        }
      ],
      "source": [
        "# Join with Airline Info\n",
        "flights_airlines_df = flights_df.join(airline_df, flights_df.AIRLINE == airline_df.IATA_CODE, \"left\") \\\n",
        "    .drop(airline_df.IATA_CODE)\n",
        "\n",
        "# Join with Origin Airport Info\n",
        "flights_airlines_airports_df = flights_airlines_df.join(\n",
        "    airport_origin_df,\n",
        "    flights_airlines_df.ORIGIN_AIRPORT == airport_origin_df.ORIGIN_AIRPORT_CODE,\n",
        "    \"left\"\n",
        ")\n",
        "\n",
        "# Join with Destination Airport Info\n",
        "flights_airlines_airports_df = flights_airlines_airports_df.join(\n",
        "    airport_destination_df,\n",
        "    flights_airlines_airports_df.DESTINATION_AIRPORT == airport_destination_df.DESTINATION_AIRPORT_CODE,\n",
        "    \"left\"\n",
        ")\n",
        "\n",
        "print(\"Joins Defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Aggregation Logic\n",
        "Define aggregations for Airline Stats, Delay Reasons, and Routes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregations Defined\n"
          ]
        }
      ],
      "source": [
        "# 1. Airline Performance Stats\n",
        "airline_stats = flights_airlines_airports_df \\\n",
        "    .filter(col(\"AIRLINE\").isNotNull()) \\\n",
        "    .groupBy(\"AIRLINE\") \\\n",
        "    .agg(\n",
        "        _sum(when(col(\"CANCELLED\") == 1, 1).otherwise(0)).alias(\"cancelled_flights\"),\n",
        "        _sum(when((col(\"CANCELLED\") == 0) & (col(\"DEPARTURE_DELAY\") <= 15), 1).otherwise(0)).alias(\"on_time_flights\"),\n",
        "        _sum(when((col(\"CANCELLED\") == 0) & (col(\"DEPARTURE_DELAY\") > 15), 1).otherwise(0)).alias(\"delayed_flights\"),\n",
        "        avg(\"DEPARTURE_DELAY\").alias(\"avg_departure_delay\"),\n",
        "        avg(\"ARRIVAL_DELAY\").alias(\"avg_arrival_delay\")\n",
        "    )\n",
        "\n",
        "airline_stats_out = airline_stats.select(\n",
        "    col(\"AIRLINE\").alias(\"airline\"),\n",
        "    col(\"cancelled_flights\"),\n",
        "    col(\"on_time_flights\"),\n",
        "    col(\"delayed_flights\"),\n",
        "    col(\"avg_departure_delay\"),\n",
        "    col(\"avg_arrival_delay\")\n",
        ")\n",
        "\n",
        "# 2. Delay by Reason Analysis\n",
        "delay_cols = [\n",
        "    \"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \n",
        "    \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\"\n",
        "]\n",
        "\n",
        "delay_df = flights_airlines_airports_df.filter(\n",
        "    (col(\"AIR_SYSTEM_DELAY\") > 0) | \n",
        "    (col(\"SECURITY_DELAY\") > 0) | \n",
        "    (col(\"AIRLINE_DELAY\") > 0) | \n",
        "    (col(\"LATE_AIRCRAFT_DELAY\") > 0) | \n",
        "    (col(\"WEATHER_DELAY\") > 0)\n",
        ")\n",
        "\n",
        "stack_expr = \"stack(5, \" + \", \".join([f\"'{c}', {c}\" for c in delay_cols]) + \") as (delay_reason, duration)\"\n",
        "\n",
        "delay_unpivoted = delay_df.selectExpr(stack_expr).filter(col(\"duration\") > 0)\n",
        "\n",
        "delay_stats = delay_unpivoted \\\n",
        "    .groupBy(\"delay_reason\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"count\"),\n",
        "        avg(\"duration\").alias(\"avg_duration\")\n",
        "    )\n",
        "\n",
        "delay_stats_out = delay_stats.select(\n",
        "    col(\"delay_reason\"),\n",
        "    col(\"count\"),\n",
        "    col(\"avg_duration\")\n",
        ")\n",
        "\n",
        "# 3. Route Analysis\n",
        "route_stats = flights_airlines_airports_df \\\n",
        "    .filter((col(\"ORIGIN_AIRPORT\").isNotNull()) & (col(\"DESTINATION_AIRPORT\").isNotNull())) \\\n",
        "    .groupBy(\n",
        "        \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\",\n",
        "        \"ORIGIN_CITY\", \"ORIGIN_STATE\", \"ORIGIN_LATITUDE\", \"ORIGIN_LONGITUDE\",\n",
        "        \"DESTINATION_CITY\", \"DESTINATION_STATE\"\n",
        "    ) \\\n",
        "    .agg(\n",
        "        avg(\"ARRIVAL_DELAY\").alias(\"avg_delay\")\n",
        "    )\n",
        "\n",
        "route_stats_out = route_stats.select(\n",
        "    col(\"ORIGIN_AIRPORT\").alias(\"original_airport\"),\n",
        "    col(\"DESTINATION_AIRPORT\").alias(\"destination_airport\"),\n",
        "    col(\"ORIGIN_CITY\").alias(\"original_city\"),\n",
        "    col(\"ORIGIN_STATE\").alias(\"original_state\"),\n",
        "    col(\"DESTINATION_CITY\").alias(\"destination_city\"),\n",
        "    col(\"DESTINATION_STATE\").alias(\"destination_state\"),\n",
        "    col(\"ORIGIN_LATITUDE\").alias(\"original_latitude\"),\n",
        "    col(\"ORIGIN_LONGITUDE\").alias(\"original_longitude\"),\n",
        "    col(\"avg_delay\")\n",
        ")\n",
        "\n",
        "print(\"Aggregations Defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Validation (Schema Check)\n",
        "Displaying schemas for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Airline Stats Schema:\n",
            "root\n",
            " |-- airline: string (nullable = true)\n",
            " |-- cancelled_flights: long (nullable = true)\n",
            " |-- on_time_flights: long (nullable = true)\n",
            " |-- delayed_flights: long (nullable = true)\n",
            " |-- avg_departure_delay: double (nullable = true)\n",
            " |-- avg_arrival_delay: double (nullable = true)\n",
            "\n",
            "Delay Stats Schema:\n",
            "root\n",
            " |-- delay_reason: string (nullable = true)\n",
            " |-- count: long (nullable = false)\n",
            " |-- avg_duration: double (nullable = true)\n",
            "\n",
            "Route Stats Schema:\n",
            "root\n",
            " |-- original_airport: string (nullable = true)\n",
            " |-- destination_airport: string (nullable = true)\n",
            " |-- original_city: string (nullable = true)\n",
            " |-- original_state: string (nullable = true)\n",
            " |-- destination_city: string (nullable = true)\n",
            " |-- destination_state: string (nullable = true)\n",
            " |-- original_latitude: double (nullable = true)\n",
            " |-- original_longitude: double (nullable = true)\n",
            " |-- avg_delay: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Airline Stats Schema:\")\n",
        "airline_stats_out.printSchema()\n",
        "\n",
        "print(\"Delay Stats Schema:\")\n",
        "delay_stats_out.printSchema()\n",
        "\n",
        "print(\"Route Stats Schema:\")\n",
        "route_stats_out.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c5f7f567",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 15:55:09 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-0970e5f5-8102-43c8-ad2b-d77a2d654cb0. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "25/12/26 15:55:09 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            "25/12/26 15:55:20 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 15:55:20 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 15:55:21 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 15:55:21 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 15:55:22 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 15:55:22 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 15:55:23 ERROR MicroBatchExecution: Query airline_stats_debug [id = 61723b50-e436-4bba-8726-9320d2fa9ca5, runId = fbbb9568-5bcc-4fdd-a775-e1ba38b8031f] terminated with error\n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----------------+---------------+---------------+-------------------+-----------------+\n",
            "|airline|cancelled_flights|on_time_flights|delayed_flights|avg_departure_delay|avg_arrival_delay|\n",
            "+-------+-----------------+---------------+---------------+-------------------+-----------------+\n",
            "+-------+-----------------+---------------+---------------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_mem = airline_stats_out.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"airline_stats_debug\") \\\n",
        "    .trigger(processingTime=\"10 seconds\") \\\n",
        "    .start()\n",
        "\n",
        "# Wait for some data to be processed\n",
        "import time\n",
        "time.sleep(15)\n",
        "\n",
        "# Query the in-memory table\n",
        "spark.sql(\"SELECT * FROM airline_stats_debug\").show(truncate=False)\n",
        "\n",
        "# Stop when done\n",
        "query_mem.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cassandra Write Logic\n",
        "Define `foreachBatch` functions to write to Cassandra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_airline_stats(batch_df, batch_id):\n",
        "    if batch_df.isEmpty():\n",
        "        print(f\"Batch {batch_id}: No data to write for airline_stats\")\n",
        "        return\n",
        "    print(f\"Writing airline_stats batch {batch_id} - {batch_df.count()} rows\")\n",
        "    try:\n",
        "        batch_df = batch_df.withColumn(\"updated_at\", current_timestamp())\n",
        "        batch_df.write \\\n",
        "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "            .mode(\"append\") \\\n",
        "            .options(table=\"airline_stats\", keyspace=\"flights_db\") \\\n",
        "            .option(\"spark.cassandra.output.consistency.level\", \"LOCAL_QUORUM\") \\\n",
        "            .save()\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing airline_stats batch {batch_id}: {e}\")\n",
        "\n",
        "def write_delay_stats(batch_df, batch_id):\n",
        "    if batch_df.isEmpty():\n",
        "        return\n",
        "    print(f\"Writing delay_stats batch {batch_id} - {batch_df.count()} rows\")\n",
        "    try:\n",
        "        batch_df = batch_df.withColumn(\"updated_at\", current_timestamp())\n",
        "        batch_df.write \\\n",
        "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "            .mode(\"append\") \\\n",
        "            .options(table=\"delay_by_reason\", keyspace=\"flights_db\") \\\n",
        "            .option(\"spark.cassandra.output.consistency.level\", \"LOCAL_QUORUM\") \\\n",
        "            .save()\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing delay_stats batch {batch_id}: {e}\")\n",
        "\n",
        "def write_route_stats(batch_df, batch_id):\n",
        "    if batch_df.isEmpty():\n",
        "        return\n",
        "    print(f\"Writing route_stats batch {batch_id} - {batch_df.count()} rows\")\n",
        "    try:\n",
        "        batch_df = batch_df.withColumn(\"updated_at\", current_timestamp())\n",
        "        batch_df.write \\\n",
        "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "            .mode(\"append\") \\\n",
        "            .options(table=\"route_stats\", keyspace=\"flights_db\") \\\n",
        "            .option(\"spark.cassandra.output.consistency.level\", \"LOCAL_QUORUM\") \\\n",
        "            .save()\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing route_stats batch {batch_id}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Start Streaming\n",
        "Start the streaming queries. \n",
        "**Note**: In a real interactive notebook, you might use `awaitTermination()` which blocks the cell. \n",
        "For verification purposes, we can use a timeout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Streams...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 14:30:24 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-a3aa3248-28ae-4c4d-bf42-04ba099c2135. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "25/12/26 14:30:24 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            "25/12/26 14:30:24 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-bc0a3233-e79c-48a4-86a2-933832b3fa3e. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "25/12/26 14:30:24 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            "25/12/26 14:30:25 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-6d6ea805-0bd5-41b3-8e49-bb61159883a5. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "25/12/26 14:30:25 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streams Started. Waiting for termination...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/26 14:30:35 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:35 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:35 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:35 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:35 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:35 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:36 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:36 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:36 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:36 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:36 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:36 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:37 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:37 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:37 WARN ClientUtils: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka\n",
            "25/12/26 14:30:37 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:37 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:37 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: \n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:38 ERROR MicroBatchExecution: Query [id = 3833d8f0-b528-4f33-8c24-732f55e5beb0, runId = 1ebec05b-2949-48ec-bab0-473e9b8fe7ab] terminated with error\n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:38 ERROR MicroBatchExecution: Query [id = 70d7322c-9aae-4a45-8c84-e4ae7ecd102d, runId = f1bff710-3f3d-40fa-8d70-822eb7df7448] terminated with error\n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n",
            "25/12/26 14:30:38 ERROR MicroBatchExecution: Query [id = ee4ee5e8-bdfa-49fd-8326-1118ebbfc259, runId = 948f6565-a5c6-42cf-8860-7abda0b5a221] terminated with error\n",
            "org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)\n",
            "\tat org.apache.kafka.clients.admin.Admin.create(Admin.java:144)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:50)\n",
            "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
            "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchEarliestOffsets(KafkaOffsetReaderAdmin.scala:288)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:244)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)\n",
            "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
            "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
            "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
            "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
            "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
            "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
            "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
            "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
            "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
            "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
            "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
            "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
            "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
            "\tat org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)\n",
            "\t... 51 more\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Queries Stopped\n"
          ]
        },
        {
          "ename": "StreamingQueryException",
          "evalue": "[STREAM_FAILED] Query [id = 3833d8f0-b528-4f33-8c24-732f55e5beb0, runId = 1ebec05b-2949-48ec-bab0-473e9b8fe7ab] terminated with exception: Failed to create new KafkaAdminClient",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStreamingQueryException\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Wait for 30 seconds to process some data\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mquery1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# query2.awaitTermination()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# query3.awaitTermination()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/pyspark/sql/streaming/query.py:219\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timeout, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[1;32m    216\u001b[0m             error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALUE_NOT_POSITIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    217\u001b[0m             message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(timeout)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    218\u001b[0m         )\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination()\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/miniconda3/envs/datalab/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mStreamingQueryException\u001b[0m: [STREAM_FAILED] Query [id = 3833d8f0-b528-4f33-8c24-732f55e5beb0, runId = 1ebec05b-2949-48ec-bab0-473e9b8fe7ab] terminated with exception: Failed to create new KafkaAdminClient"
          ]
        }
      ],
      "source": [
        "# Start all streaming queries\n",
        "print(\"Starting Streams...\")\n",
        "\n",
        "query1 = airline_stats_out.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .foreachBatch(write_airline_stats) \\\n",
        "    .trigger(processingTime=\"10 seconds\") \\\n",
        "    .start()\n",
        "\n",
        "query2 = delay_stats_out.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .foreachBatch(write_delay_stats) \\\n",
        "    .trigger(processingTime=\"10 seconds\") \\\n",
        "    .start()\n",
        "\n",
        "query3 = route_stats_out.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .foreachBatch(write_route_stats) \\\n",
        "    .trigger(processingTime=\"10 seconds\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"Streams Started. Waiting for termination...\")\n",
        "# For testing/verification, we can wait for a short duration or until stopped manually.\n",
        "# In production/long-running, use query.awaitTermination()\n",
        "\n",
        "# Using a shorter timeout for automated verification if run via script\n",
        "import time\n",
        "try:\n",
        "    # Wait for 30 seconds to process some data\n",
        "    query1.awaitTermination(30)\n",
        "    # query2.awaitTermination()\n",
        "    # query3.awaitTermination()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping queries...\")\n",
        "finally:\n",
        "    query1.stop()\n",
        "    query2.stop()\n",
        "    query3.stop()\n",
        "    print(\"Queries Stopped\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datalab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
